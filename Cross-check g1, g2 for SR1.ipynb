{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb844566240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### run imports\n",
    "%run \"Initialize.ipynb\"\n",
    "matplotlib.rc('font', size=20)                   # Use big fonts...\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)    # ... and big plots\n",
    "#hax.make_minitrees=False #I just don't feel like making minitrees for now\n",
    "### Perceptually uniform, good for greyscale and dichromacy: magma, plasma, inferno and viridis\n",
    "### ROOTish: jet\n",
    "\n",
    "plt.set_cmap('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# Get pax values\n",
    "from pax import units, configuration, datastructure\n",
    "pax_config = configuration.load_configuration('XENON1T')\n",
    "n_channels = pax_config['DEFAULT']['n_channels']\n",
    "pmts = pax_config['DEFAULT']['pmts']\n",
    "tpc_height = pax_config['DEFAULT']['tpc_length']\n",
    "tpc_radius = pax_config['DEFAULT']['tpc_radius']\n",
    "gains = pax_config['DEFAULT']['gains']\n",
    "# get channel number of busy on\n",
    "busy_on_ch = pax_config['DEFAULT']['channels_in_detector']['busy_on'][0]\n",
    "\n",
    "\n",
    "\n",
    "# hax configuration\n",
    "import hax\n",
    "from hax import cuts\n",
    "\n",
    "hax.__version__\n",
    "hax.init(experiment='XENON1T',\n",
    "         raw_data_access_mode='local',\n",
    "         raw_data_local_path='/project/lgrandi/xenon1t/raw',\n",
    "        main_data_paths=['/project/lgrandi/xenon1t/processed/pax_v6.6.5' , \n",
    "                         '/project2/lgrandi/xenon1t/processed/pax_v6.6.5'], # add here correct path for AmBe\n",
    "        #minitree_paths = ['/project*/lgrandi/xenon1t/minitrees', \n",
    "         #                 '/project*/lgrandi/xenon1t/minitrees/latest',\n",
    "          #               '.', '/project*/lgrandi/xenon1t/minitrees/pax_v6.6.5'],\n",
    "        #minitree_paths = ['/home/fieguth/DEC','*'],\n",
    "         pax_version_policy= '6.6.5'  )\n",
    "        #minitree_paths = ['/project*/lgrandi/xenon1t/minitrees/latest'],\n",
    "         #pax_version_policy= '6.6.5'  )\n",
    "\n",
    "\n",
    "\n",
    "datasets = hax.runs.datasets # this variable holds all dataset info\n",
    "\n",
    "#treemaker for cs2_bottom from Adam Brown\n",
    "from s2_top_bottom_new import S2TopBottom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Take all background datasets which possibly contain 164 keV\n",
    "#dsets = datasets[(datasets.source__type == 'none')| (datasets.source__type == 'None')]\n",
    "dsets = hax.runs.tags_selection(include=['blinded'], exclude=['bad', 'messy', '*trip', '*quake','test'])\n",
    "dsets = dsets[(dsets.source__type == 'none')| (dsets.source__type == 'None')] # \n",
    "dsets = dsets[(dsets.location != '')]\n",
    "dsets['run_time_s'] = pd.to_timedelta(pd.to_datetime(dsets.end) - pd.to_datetime(dsets.start)).dt.seconds\n",
    "dsets = dsets[dsets.run_time_s > 3600] # select only runs of an hour or more, CHECK IF NECESSARY FOR AMBE\n",
    "# some of the datasets had anomalously high background rates. I didn't use these datasets for the analysis.\n",
    "# dsets['background_rate'] = dsets.trigger__events_built/dsets.run_time_s # background rate (avg. events/s)\n",
    "\n",
    "# select data range\n",
    "dsets = dsets[(dsets.start > pd.to_datetime('02/01/2017')) & (dsets.end < pd.to_datetime('06/05/2017'))]\n",
    "#dsets = dsets[(dsets.start > pd.to_datetime('1/10/2017')) & (dsets.end < pd.to_datetime('1/18/2017'))]\n",
    "dsets['start_date'] = dsets.start.dt.date\n",
    "\n",
    "run_names = dsets.name\n",
    "\n",
    "# get rid of problematic runs\n",
    "bad_runs = ['161204_1517','170111_031','170111_0314'] # n'o minitree'\n",
    "\n",
    "for run in bad_runs:\n",
    "    run_names = run_names[run_names != run]\n",
    "    dsets  = dsets[dsets.name != run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run 170202_1747: Making Basics minitree: 100%|██████████| 21603/21603 [00:35<00:00, 602.48it/s] \n",
      "Run 170202_1747: Making Extended minitree: 100%|██████████| 21603/21603 [01:00<00:00, 356.75it/s] \n",
      "/project/lgrandi/anaconda3/envs/pax_head/lib/python3.4/site-packages/pandas/computation/align.py:98: RuntimeWarning: divide by zero encountered in log10\n",
      "  ordm = np.log10(abs(reindexer_size - term_axis_size))\n",
      "Run 170202_1747: Making Basics minitree: 100%|██████████| 21603/21603 [00:36<00:00, 589.49it/s] \n",
      "Run 170202_1847: Making Basics minitree: 100%|██████████| 19490/19490 [00:37<00:00, 525.42it/s]\n",
      "Run 170419_1430: Making Basics minitree: 100%|██████████| 19648/19648 [00:38<00:00, 514.89it/s]\n",
      "Run 170209_1211: Making Basics minitree: 100%|██████████| 19551/19551 [00:38<00:00, 505.85it/s]\n",
      "Run 170419_1430: Making Extended minitree:   1%|          | 181/19648 [00:00<04:10, 77.58it/s]]\n",
      "Run 170202_1747: Making Extended minitree: 100%|██████████| 21603/21603 [01:06<00:00, 323.05it/s] \n",
      "Run 170202_1847: Making Extended minitree: 100%|██████████| 19490/19490 [01:06<00:00, 293.17it/s]\n",
      "Run 170419_1430: Making Extended minitree: 100%|██████████| 19648/19648 [01:06<00:00, 296.68it/s]\n",
      "Run 170203_0349: Making Extended minitree: 100%|██████████| 19207/19207 [01:06<00:00, 289.11it/s]\n",
      "Run 170209_1211: Making Extended minitree: 100%|██████████| 19551/19551 [01:07<00:00, 289.60it/s]\n",
      "Run 170419_1906: Making Basics minitree: 100%|██████████| 19033/19033 [00:39<00:00, 481.66it/s]\n",
      "Run 170419_1605: Making Basics minitree: 100%|██████████| 19565/19565 [00:39<00:00, 489.38it/s]\n",
      "Run 170419_2006: Making Basics minitree: 100%|██████████| 19573/19573 [00:39<00:00, 494.11it/s]\n",
      "Run 170419_2206: Making Basics minitree: 100%|██████████| 19007/19007 [00:40<00:00, 470.52it/s]\n",
      "Run 170419_2106: Making Basics minitree: 100%|██████████| 19223/19223 [00:41<00:00, 468.68it/s]\n",
      "Run 170419_1906: Making Extended minitree: 100%|██████████| 19033/19033 [01:09<00:00, 274.52it/s]\n",
      "Run 170419_1605: Making Extended minitree: 100%|██████████| 19565/19565 [01:09<00:00, 282.66it/s]\n",
      "Run 170419_2006: Making Extended minitree: 100%|██████████| 19573/19573 [01:09<00:00, 282.52it/s]\n",
      "Run 170419_2206: Making Extended minitree: 100%|██████████| 19007/19007 [01:07<00:00, 279.70it/s]\n",
      "Run 170419_2106: Making Extended minitree: 100%|██████████| 19223/19223 [01:09<00:00, 277.03it/s]\n",
      "Run 170419_2307: Making Basics minitree: 100%|██████████| 19468/19468 [00:37<00:00, 516.77it/s]\n",
      "Run 170420_0107: Making Basics minitree: 100%|██████████| 19375/19375 [00:37<00:00, 520.50it/s]\n",
      "Run 170420_0007: Making Basics minitree: 100%|██████████| 19250/19250 [00:37<00:00, 512.07it/s]\n",
      "Run 170420_0208: Making Basics minitree: 100%|██████████| 19056/19056 [00:38<00:00, 498.96it/s]\n",
      "Run 170209_1312: Making Basics minitree: 100%|██████████| 19327/19327 [00:38<00:00, 507.85it/s]\n",
      "Run 170420_0007: Making Extended minitree: 100%|██████████| 19250/19250 [01:03<00:00, 305.36it/s]\n",
      "Run 170419_2307: Making Extended minitree: 100%|██████████| 19468/19468 [01:05<00:00, 297.62it/s]\n",
      "Run 170420_0107: Making Extended minitree: 100%|██████████| 19375/19375 [01:05<00:00, 294.99it/s]\n",
      "Run 170420_0208: Making Extended minitree: 100%|██████████| 19056/19056 [01:05<00:00, 291.53it/s]\n",
      "Run 170209_1312: Making Extended minitree: 100%|██████████| 19327/19327 [01:06<00:00, 289.87it/s]\n",
      "Run 170420_0308: Making Basics minitree: 100%|██████████| 19503/19503 [00:37<00:00, 516.32it/s]\n",
      "Run 170420_0408: Making Basics minitree: 100%|██████████| 19439/19439 [00:36<00:00, 531.36it/s]\n",
      "Run 170420_0508: Making Basics minitree: 100%|██████████| 19234/19234 [00:37<00:00, 508.67it/s]\n",
      "Run 170420_0608: Making Basics minitree: 100%|██████████| 19398/19398 [00:38<00:00, 506.99it/s]\n",
      "Run 170420_0708: Making Basics minitree: 100%|██████████| 19374/19374 [00:38<00:00, 505.31it/s]]\n",
      "Run 170420_0408: Making Extended minitree: 100%|██████████| 19439/19439 [01:03<00:00, 304.22it/s]\n",
      "Run 170420_0308: Making Extended minitree: 100%|██████████| 19503/19503 [01:04<00:00, 301.99it/s]\n",
      "Run 170420_0508: Making Extended minitree: 100%|██████████| 19234/19234 [01:03<00:00, 304.40it/s]\n",
      "Run 170420_0608: Making Extended minitree: 100%|██████████| 19398/19398 [01:04<00:00, 302.40it/s]\n",
      "Run 170420_0708: Making Extended minitree: 100%|██████████| 19374/19374 [01:04<00:00, 302.38it/s]\n",
      "Run 170420_1009: Making Basics minitree: 100%|██████████| 19116/19116 [00:36<00:00, 524.83it/s]\n",
      "Run 170420_0909: Making Basics minitree: 100%|██████████| 19539/19539 [00:37<00:00, 520.53it/s]\n",
      "Run 170420_0809: Making Basics minitree: 100%|██████████| 19487/19487 [00:37<00:00, 516.89it/s]\n",
      "Run 170420_1109: Making Basics minitree: 100%|██████████| 19464/19464 [00:37<00:00, 514.29it/s]]\n",
      "Run 170420_1209: Making Basics minitree: 100%|██████████| 19261/19261 [00:37<00:00, 517.84it/s]]\n",
      "Run 170420_1009: Making Extended minitree: 100%|██████████| 19116/19116 [01:02<00:00, 306.06it/s]\n",
      "Run 170420_0909: Making Extended minitree: 100%|██████████| 19539/19539 [01:04<00:00, 302.24it/s]\n",
      "Run 170420_0809: Making Extended minitree: 100%|██████████| 19487/19487 [01:04<00:00, 301.43it/s]\n",
      "Run 170420_1109: Making Extended minitree: 100%|██████████| 19464/19464 [01:06<00:00, 292.74it/s]\n",
      "Run 170420_1209: Making Extended minitree: 100%|██████████| 19261/19261 [01:09<00:00, 278.67it/s]\n",
      "Run 170209_1747: Making Basics minitree: 100%|██████████| 19437/19437 [00:38<00:00, 505.38it/s]\n",
      "Run 170420_1310: Making Basics minitree: 100%|██████████| 19355/19355 [00:36<00:00, 524.29it/s]\n",
      "Run 170420_1410: Making Basics minitree: 100%|██████████| 19491/19491 [00:39<00:00, 492.28it/s]]\n",
      "Run 170420_1510: Making Basics minitree: 100%|██████████| 19286/19286 [00:38<00:00, 501.85it/s]]\n",
      "Run 170420_1610: Making Basics minitree: 100%|██████████| 19273/19273 [00:40<00:00, 480.31it/s]]\n",
      "Run 170209_1747: Making Extended minitree: 100%|██████████| 19437/19437 [01:02<00:00, 310.27it/s]\n",
      "Run 170420_1310: Making Extended minitree: 100%|██████████| 19355/19355 [01:08<00:00, 366.90it/s]\n",
      "Run 170420_1410: Making Extended minitree: 100%|██████████| 19491/19491 [01:10<00:00, 276.15it/s]\n",
      "Run 170420_1510: Making Extended minitree: 100%|██████████| 19286/19286 [01:10<00:00, 273.14it/s]\n",
      "Run 170420_1610: Making Extended minitree: 100%|██████████| 19273/19273 [01:08<00:00, 279.75it/s]\n",
      "Run 170420_1710: Making Basics minitree: 100%|██████████| 19449/19449 [00:36<00:00, 529.65it/s]\n",
      "Run 170420_1810: Making Basics minitree: 100%|██████████| 19113/19113 [00:38<00:00, 496.01it/s]]\n",
      "Run 170420_1911: Making Basics minitree: 100%|██████████| 19613/19613 [00:38<00:00, 506.39it/s]]\n",
      "Run 170420_2011: Making Basics minitree: 100%|██████████| 19230/19230 [00:39<00:00, 490.33it/s]]\n",
      "Run 170420_2111: Making Basics minitree: 100%|██████████| 19423/19423 [00:37<00:00, 512.48it/s]]\n",
      "Run 170420_2111: Making Extended minitree:  53%|█████▎    | 10327/19423 [00:37<01:02, 146.38it/s]"
     ]
    }
   ],
   "source": [
    "# load data or create minitrees from data\n",
    "# a preselection for the activated lines is done by removing neutrons in AmBe and Kr83m in the respective data, additionally gas events are removed and z is cut for the final fiducial volume\n",
    "preselect=['z>-81.9' ,'z<-20','x<47','y<47','x>-47','y>-47','s2_area_fraction_top < 0.74', 'cs2>0', 'cs1>0']\n",
    "#df = hax.minitrees.load(run_names, ['Basics',S2TopBottom,'Extended'], preselection=preselect, force_reload=False, num_workers = 4)\n",
    "df = hax.minitrees.load(run_names, ['Basics','Extended'], preselection=preselect, force_reload=True, num_workers = 5)\n",
    "#hax.minitrees.save_cache_file(df,'cached_minitrees.mts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df = hax.minitrees.load(run_names, ['Basics', 'TotalProperties', 'Fundamentals'], \n",
    "#                        cache_file = 'some_file_name')\n",
    "#df = hax.minitrees.load_cache_file('some_file_name')\n",
    "\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-edb14fa83f77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe_to_wiki\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Table : Preselection overview'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Jelle provided me this to make wiki tables directly, big thanks!\n",
    "\n",
    "def dataframe_to_wiki(df, float_digits=5, title='Awesome table'):\n",
    "    table = '^ %s ' % title + '^' * (len(df.columns) - 1) + '^\\n'\n",
    "    table += '^ ' + ' ^ '.join(df.columns) + ' ^\\n'\n",
    "    def do_round(x):\n",
    "        if isinstance(x, float):\n",
    "            return round(x, float_digits)\n",
    "        return x\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        table += \"| \" + ' | '.join([str(do_round(x)) for x in row.values.tolist()]) + ' |\\n'\n",
    "    return table\n",
    "\n",
    "print(dataframe_to_wiki(cuts.history(df), title='Table : Preselection overview'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# organize the data by day - taken from LOW-ER, but still useful\n",
    "df = pd.merge(df, dsets[['number', 'start_date']], how = 'left', \n",
    "              left_on = 'run_number', right_on = 'number')\n",
    "\n",
    "# list of dates of runs\n",
    "dates = df.start_date.unique()\n",
    " \n",
    "#obtain the total runtime\n",
    "run_time_tot_s = dsets.run_time_s.sum()\n",
    "print('Dataset metadata:')\n",
    "print('%i datasets are used in this analysis.' % len(run_names))\n",
    "print('The total runtime (sum of all the run times) is about %.3g hours.' % (run_time_tot_s/(60*60)))\n",
    "print('There are %.f events loaded' % len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['cs2bottom']=df.cs2_bottom_new\n",
    "df['r_squared'] = df.x**2 + df.y**2  # Define a radial coordinate\n",
    "df['r'] = np.sqrt(df.x**2 + df.y**2)\n",
    "df['cs1cs2blog10'] = np.log10(df['cs2bottom']/df['cs1']) # define log-variable for useful plots\n",
    "print(tpc_height)\n",
    "# fiducial volume variables\n",
    "z_min         = - 83.45 # cm 53.45\n",
    "z_max         = - 13.45 # cm\n",
    "r_max = 39.5\n",
    "\n",
    "r_squared_max = r_max**2 # cm^2\n",
    "r_tpc = (tpc_radius-5)**2\n",
    "rho_xenon     = 3.1  # grams per cubic centimeter\n",
    "fid_vol       = np.pi * r_squared_max * (z_max - z_min) # in units of cubic centimeters\n",
    "n_kg          = fid_vol * rho_xenon / 1000\n",
    "exposure = n_kg * run_time_tot_s / (60*60*24)\n",
    "\n",
    "print('%g kg of xenon are within the fiducial volume.' % n_kg)\n",
    "\n",
    "# some variable limits for further use\n",
    "cs1_min       = 1 # pe for starters\n",
    "cs2_min       = 150 # pe minimum trigger\n",
    "cs1_max       = 31000 #pe resulting from alphas\n",
    "cs2_max       = 1e7 #pe random high number so far\n",
    "ces_min       = 0 # keV\n",
    "ces_max       = 700 # keV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "################################### #### All cuts are here ############ ################################### \n",
    "from lax.lichens import sciencerun0 \n",
    "df_work = df \n",
    "cut = sciencerun0.FiducialCylinder1T() \n",
    "cut2 = sciencerun0.S2AreaFractionTop() \n",
    "cut3= sciencerun0.S1SingleScatter()\n",
    "cut4= sciencerun0.S2SingleScatter()\n",
    "\n",
    "df_work = cut.process(df_work) \n",
    "df_work = cut2.process(df_work) \n",
    "df_work = cut3.process(df_work) \n",
    "df_work = cut4.process(df_work) \n",
    "\n",
    "#Cuts \n",
    "\n",
    "df_work = cuts.selection(df_work, df_work['CutFiducialCylinder1T'], desc='CutFiducialCylinder1T')\n",
    "df_work = cuts.selection(df_work, df_work['CutS2AreaFractionTop'], desc='CutS2AreaFractionTop') \n",
    "#df_work =cuts.selection(df_work,df_work.largest_other_s2<0.03*df_work.s2,'S2 single scatter cut')\n",
    "df_work = cuts.selection(df_work, df_work['CutS2SingleScatter'], desc='CutS2SingleScatter') \n",
    "df_work = cuts.selection(df_work, df_work['CutS1SingleScatter'], desc='CutS1SingleScatter') \n",
    "\n",
    "cuts.history(df_work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.hist2d(df_work['cs1'], df_work['cs2bottom']/100, \n",
    "           bins=400, range=([0,17000],[0,15000]), norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar(label='Number of events')\n",
    "plt.xlabel('cS1 [pe]')\n",
    "plt.ylabel('cS2$_b$ [pe]')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.hist2d(np.sqrt(np.add(np.power(df_work['x'],2),np.power(df_work['y'],2))), df_work['z'], \n",
    "           bins=400, range=([0,50],[-100,0]), norm=matplotlib.colors.LogNorm())\n",
    "plt.colorbar(label='Number of events')\n",
    "plt.xlabel('cS1 [pe]')\n",
    "plt.ylabel('cS2$_b$ [pe]')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Activated Xe at 163.9 keV and 232.2 keV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import root_numpy\n",
    "\n",
    "ROOT.gROOT.SetStyle(\"Plain\");   \n",
    "ROOT.gStyle.SetOptStat(1000000010)\n",
    "ROOT.gStyle.SetPalette(57);     \n",
    "ROOT.gStyle.SetOptTitle(0);     \n",
    "ROOT.gStyle.SetOptFit(111)\n",
    "ROOT.TVirtualFitter.SetDefaultFitter(\"Minuit\");\n",
    "\n",
    "df_active = cuts.selection(df_work, df_work['CutFiducialCylinder1T'], desc='CutFiducialCylinder1T')\n",
    "t164_236 = root_numpy.array2tree(df_active.to_records())\n",
    "c = ROOT.TCanvas('c','c',900,600)\n",
    "\n",
    "t164_236.Draw('cs2bottom/100:cs1>>h5(200,800,2800,70,200,900)','','COLZ')\n",
    "hist_s2_s1_164_236kev = ROOT.gDirectory.Get('h5')\n",
    "hist_s2_s1_164_236kev.GetXaxis().SetTitle('cs1')\n",
    "hist_s2_s1_164_236kev.GetYaxis().SetTitle('cs2_b')\n",
    "hist_s2_s1_164_236kev.Sumw2(1)\n",
    "\n",
    "# Reposition the stats box\n",
    "ROOT.gPad.Update()\n",
    "st = hist_s2_s1_164_236kev.FindObject(\"stats\")\n",
    "st.SetX1NDC(0.625)\n",
    "st.SetX2NDC(0.9)\n",
    "st.SetY1NDC(0.275)\n",
    "st.SetY2NDC(0.875)\n",
    "\n",
    "\n",
    "#f7 = ROOT.TF2(\"f7\",\"([0]*TMath::Exp(-0.5*(TMath::Power((((x-[1])*cos(-TMath::ATan([2]/[1])+TMath::Pi()/2)-(y-[2])*sin(-TMath::ATan([2]/[1])+TMath::Pi()/2))/[3]),2)+TMath::Power((((x-[1])*sin(-TMath::ATan([2]/[1])+TMath::Pi()/2)+(y-[2])*cos(-TMath::ATan([2]/[1])+TMath::Pi()/2))/[4]),2))))+([5]*TMath::Exp(-0.5*(TMath::Power((((x-[6])*cos(-TMath::ATan([7]/[6])+TMath::Pi()/2)-(y-[7])*sin(-TMath::ATan([7]/[6])+TMath::Pi()/2))/[8]),2)+TMath::Power((((x-[6])*sin(-TMath::ATan([7]/[6])+TMath::Pi()/2)+(y-[7])*cos(-TMath::ATan([7]/[6])+TMath::Pi()/2))/[9]),2))))\",170,310,170,350)\n",
    "#f7.SetParameter(0, 20)\n",
    "#f7.SetParameter(1, 250)\n",
    "#f7.SetParLimits(1,240,265)\n",
    "#f7.SetParameter(2, 300)\n",
    "#f7.SetParLimits(2,280,320)\n",
    "#f7.SetParameter(3, 60)\n",
    "#f7.SetParameter(4, 80)\n",
    "#f7.SetParameter(5, amplitude_80kev)\n",
    "#f7.FixParameter(6, mu_x_80kev)\n",
    "#f7.FixParameter(7, mu_y_80kev)\n",
    "#f7.FixParameter(8, a_80kev)\n",
    "#f7.FixParameter(9, b_80kev)\n",
    "#f7.SetLineColor(1)\n",
    "#f7.SetLineWidth(2)\n",
    "#f7.SetContour(15, ) #What kind of contours are drawn by default anyway?\n",
    "\n",
    "\n",
    "f6 = ROOT.TF2(\"f6\",\"([0]*TMath::Exp(-0.5*(TMath::Power((((x-[1])*cos([3])-(y-[2])*sin([3]))/[4]),2)+TMath::Power((((x-[1])*sin([3])+(y-[2])*cos([3]))/[5]),2))))+([6]*TMath::Exp(-0.5*(TMath::Power((((x-[7])*cos([9])-(y-[8])*sin([9]))/[10]),2)+TMath::Power((((x-[7])*sin([9])+(y-[8])*cos([9]))/[11]),2))))+[12]\"\n",
    "              ,700,2200,200,900)\n",
    "f6.SetParameter(0, 20)\n",
    "f6.SetParLimits(0,0,1000)\n",
    "f6.SetParameter(1, 1221)\n",
    "#f6.SetParLimits(1,240,265)\n",
    "f6.SetParameter(2, 414.9)\n",
    "f6.SetParLimits(2,350,450)\n",
    "f6.SetParameter(3,0.847)\n",
    "f6.SetParameter(3, 0.6)\n",
    "f6.SetParLimits(3,0.5,1.0);\n",
    "f6.SetParameter(4, 37)\n",
    "f6.SetParameter(5, 90)\n",
    "f6.SetParameter(6, 5)\n",
    "f6.SetParLimits(6, 0,1000)\n",
    "f6.SetParameter(7, 1730)\n",
    "f6.SetParLimits(7,1600,1800)\n",
    "f6.SetParameter(8, 608)\n",
    "f6.SetParLimits(8,490,720)\n",
    "f6.SetParameter(9, 0.6)\n",
    "f6.SetParLimits(9, 0.5,0.85)\n",
    "f6.SetParameter(10, 110)\n",
    "f6.SetParameter(11, 33)\n",
    "f6.SetLineColor(2)\n",
    "f6.SetLineWidth(3)\n",
    "f6.SetContour(5, ) #What kind of contours are drawn by default anyway?\n",
    "\n",
    "f6.SetParName(0, \"A_{163.9 keV}\")\n",
    "f6.SetParName(1, \"#mu_{S1, 163.9 keV}\")\n",
    "f6.SetParName(2, \"#mu_{S2, 163.9 keV}\")\n",
    "f6.SetParName(3, \"#phi_{163.9 keV}\")\n",
    "f6.SetParName(4, \"a_{163.9 keV}\")\n",
    "f6.SetParName(5, \"b_{163.9 keV}\")\n",
    "f6.SetParName(6, \"A_{236.2 keV}\")\n",
    "f6.SetParName(7, \"#mu_{S1, 236.2 keV}\")\n",
    "f6.SetParName(8, \"#mu_{S2, 236.2 keV}\")\n",
    "f6.SetParName(9, \"#phi_{236.2 keV}\")\n",
    "f6.SetParName(10, \"a_{236.2 keV}\")\n",
    "f6.SetParName(11, \"b_{236.2 keV}\")\n",
    "f6.SetParName(12, \"Background\")\n",
    "\n",
    "#ROOT.gPad.SetLogz()\n",
    "\n",
    "\n",
    "fit = hist_s2_s1_164_236kev.Fit('f6', \"LER\")\n",
    "hist_s2_s1_164_236kev.GetXaxis().SetTitle('cS1 [pe]')\n",
    "hist_s2_s1_164_236kev.GetYaxis().SetTitle('cS2_{b}/100 [pe]')\n",
    "hist_s2_s1_164_236kev.GetYaxis().SetTitleOffset(1.3)\n",
    "hist_s2_s1_164_236kev.Draw(\"COLZ\")\n",
    "\n",
    "\n",
    "\n",
    "# Get the right errors with option \"E\". Here a mean error is calculated from the asymmetric errors MINOS returns.\n",
    "# The asymmetric errors can be accessed by r.LowerError(<parameter>) and r.UpperError(<parameter>)\n",
    "# Also observe that the \"S\" option is used which lets you access the full covariance matrix, etc. \n",
    "r = ROOT.TFitResultPtr()\n",
    "r = hist_s2_s1_164_236kev.Fit('f6', \"RLES\")\n",
    "mu_x_164kev_err=r.Error(1)\n",
    "mu_y_164kev_err=r.Error(2)\n",
    "phi_164kev_err=r.Error(3)\n",
    "mu_x_236kev_err=r.Error(7)\n",
    "mu_y_236kev_err=r.Error(8)\n",
    "phi_236kev_err=r.Error(9)\n",
    "\n",
    "mu_x_164kev=f6.GetParameter(1)\n",
    "mu_y_164kev=f6.GetParameter(2)\n",
    "phi_164kev=f6.GetParameter(3)\n",
    "\n",
    "mu_x_236kev=f6.GetParameter(7)\n",
    "mu_y_236kev=f6.GetParameter(8)\n",
    "phi_236kev=f6.GetParameter(9)\n",
    "\n",
    "\n",
    "#print(\"Light yield is\", mu_x_164_236kev/164, \"PE/keV\")\n",
    "#print(\"Charge yield is\", mu_y_164_236kev/100, \"PE/keV\")\n",
    "#print(\"phi = \", phi_164_236kev)\n",
    "#m = ROOT.TMath.Tan(phi_164_236kev*3.141/1164)\n",
    "#print(\"Slope of the main axis is\", m)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c.Update()\n",
    "\n",
    "\n",
    "c.SaveAs('s2_s1_164_236kev.png')\n",
    "c.SaveAs('s2_s1_164_236kev.pdf')\n",
    "from IPython.display import Image\n",
    "Image(filename='s2_s1_164_236kev.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## $^{60}$Co at 1173.2 keV and 1332.5 keV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import root_numpy\n",
    "\n",
    "ROOT.gROOT.SetStyle(\"Plain\");   \n",
    "ROOT.gStyle.SetOptStat(1000000010)\n",
    "ROOT.gStyle.SetPalette(57);     \n",
    "ROOT.gStyle.SetOptTitle(0);     \n",
    "ROOT.gStyle.SetOptFit(111)\n",
    "ROOT.TVirtualFitter.SetDefaultFitter(\"Minuit\");\n",
    "\n",
    "df_cobalt=cuts.selection(df_work,df_work.largest_other_s2<0.01*df_work.s2,'Strict S2 single scatter cut')\n",
    "df_cobalt=cuts.selection(df_cobalt,np.sqrt(np.add(np.power(df_cobalt.x,2),np.power(df_cobalt.y,2)))<35,'Radial cut')\n",
    "\n",
    "\n",
    "t164_236 = root_numpy.array2tree(df_cobalt.to_records())\n",
    "\n",
    "c = ROOT.TCanvas('c','c',900,600)\n",
    "\n",
    "t164_236.Draw('cs2bottom/100:cs1>>h5(140,5000,9000,160,3000,7000)','','COLZ')\n",
    "hist_s2_s1_1173_1332kev = ROOT.gDirectory.Get('h5')\n",
    "hist_s2_s1_1173_1332kev.GetXaxis().SetTitle('cs1')\n",
    "hist_s2_s1_1173_1332kev.GetYaxis().SetTitle('cs2_b')\n",
    "hist_s2_s1_1173_1332kev.Sumw2(1)\n",
    "\n",
    "# Reposition the stats box\n",
    "ROOT.gPad.Update()\n",
    "st = hist_s2_s1_1173_1332kev.FindObject(\"stats\")\n",
    "st.SetX1NDC(0.725)\n",
    "st.SetX2NDC(0.9)\n",
    "st.SetY1NDC(0.275)\n",
    "st.SetY2NDC(0.875)\n",
    "\n",
    "\n",
    "f6 = ROOT.TF2(\"f6\",\"([0]*TMath::Exp(-0.5*(TMath::Power((((x-[1])*cos([3])-(y-[2])*sin([3]))/[4]),2)+TMath::Power((((x-[1])*sin([3])+(y-[2])*cos([3]))/[5]),2))))+([6]*TMath::Exp(-0.5*(TMath::Power((((x-[7])*cos([9])-(y-[8])*sin([9]))/[10]),2)+TMath::Power((((x-[7])*sin([9])+(y-[8])*cos([9]))/[11]),2))))+[12]\"\n",
    "              ,5700,8500,3500,6500)\n",
    "f6.SetParameter(0, 30)\n",
    "f6.SetParLimits(0,0,100)\n",
    "f6.SetParameter(1, 6500)\n",
    "f6.SetParLimits(1,5400,7600)\n",
    "f6.SetParameter(2, 4500.9)\n",
    "f6.SetParLimits(2,3500,5450)\n",
    "f6.SetParameter(3,0.847)\n",
    "f6.SetParameter(3, 0.5)\n",
    "f6.SetParLimits(3,0.5,0.85);\n",
    "f6.SetParameter(4, 600)\n",
    "f6.SetParameter(5, 270)\n",
    "f6.SetParameter(6, 20)\n",
    "f6.SetParLimits(6, 0,100)\n",
    "f6.SetParameter(7, 7500)\n",
    "f6.SetParLimits(7,6000,8800)\n",
    "f6.SetParameter(8, 5250)\n",
    "f6.SetParLimits(8,4900,7200)\n",
    "f6.SetParameter(9, 0.5)\n",
    "f6.SetParLimits(9, 0.5,0.85)\n",
    "f6.SetParameter(10, 600)\n",
    "f6.SetParameter(11, 270)\n",
    "f6.SetParameter(12, 1)\n",
    "f6.SetParLimits(12, 0, 5)\n",
    "f6.SetLineColor(2)\n",
    "f6.SetLineWidth(3)\n",
    "f6.SetContour(5, ) #What kind of contours are drawn by default anyway?\n",
    "\n",
    "f6.SetParName(0, \"A_{1173 keV}\")\n",
    "f6.SetParName(1, \"#mu_{S1, 1173 keV}\")\n",
    "f6.SetParName(2, \"#mu_{S2, 1173 keV}\")\n",
    "f6.SetParName(3, \"#phi_{1173 keV}\")\n",
    "f6.SetParName(4, \"a_{1173 keV}\")\n",
    "f6.SetParName(5, \"b_{1173 keV}\")\n",
    "f6.SetParName(6, \"A_{1332 keV}\")\n",
    "f6.SetParName(7, \"#mu_{S1, 1332 keV}\")\n",
    "f6.SetParName(8, \"#mu_{S2, 1332 keV}\")\n",
    "f6.SetParName(9, \"#phi_{1332 keV}\")\n",
    "f6.SetParName(10, \"a_{1332 keV}\")\n",
    "f6.SetParName(11, \"b_{1332 keV}\")\n",
    "f6.SetParName(12, \"Background\")\n",
    "\n",
    "#ROOT.gPad.SetLogz()\n",
    "\n",
    "\n",
    "fit = hist_s2_s1_1173_1332kev.Fit('f6', \"LER\")\n",
    "hist_s2_s1_1173_1332kev.GetXaxis().SetTitle('cS1 [pe]')\n",
    "hist_s2_s1_1173_1332kev.GetYaxis().SetTitle('cS2_{b}/100 [pe]')\n",
    "hist_s2_s1_1173_1332kev.GetYaxis().SetTitleOffset(1.3)\n",
    "hist_s2_s1_1173_1332kev.Draw(\"COLZ\")\n",
    "\n",
    "\n",
    "\n",
    "# Get the right errors with option \"E\". Here a mean error is calculated from the asymmetric errors MINOS returns.\n",
    "# The asymmetric errors can be accessed by r.LowerError(<parameter>) and r.UpperError(<parameter>)\n",
    "# Also observe that the \"S\" option is used which lets you access the full covariance matrix, etc. \n",
    "r = ROOT.TFitResultPtr()\n",
    "r = hist_s2_s1_1173_1332kev.Fit('f6', \"RLES\")\n",
    "mu_x_1173kev_err=r.Error(1)\n",
    "mu_y_1173kev_err=r.Error(2)\n",
    "phi_1173kev_err=r.Error(3)\n",
    "mu_x_1332kev_err=r.Error(7)\n",
    "mu_y_1332kev_err=r.Error(8)\n",
    "phi_1332kev_err=r.Error(9)\n",
    "\n",
    "mu_x_1173kev=f6.GetParameter(1)\n",
    "mu_y_1173kev=f6.GetParameter(2)\n",
    "phi_1173kev=f6.GetParameter(3)\n",
    "\n",
    "mu_x_1332kev=f6.GetParameter(7)\n",
    "mu_y_1332kev=f6.GetParameter(8)\n",
    "phi_1332kev=f6.GetParameter(9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c.Update()\n",
    "\n",
    "\n",
    "c.SaveAs('s2_s1_1173_1332kev.png')\n",
    "c.SaveAs('s2_s1_1173_1332kev.pdf')\n",
    "from IPython.display import Image\n",
    "Image(filename='s2_s1_1173_1332kev.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## $^{83m}$Kr 41.5 keV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import root_numpy\n",
    "\n",
    "ROOT.gROOT.SetStyle(\"Plain\");   \n",
    "ROOT.gStyle.SetOptStat(1000000010)\n",
    "ROOT.gStyle.SetPalette(57);     \n",
    "ROOT.gStyle.SetOptTitle(0);     \n",
    "ROOT.gStyle.SetOptFit(111)\n",
    "ROOT.TVirtualFitter.SetDefaultFitter(\"Minuit\");\n",
    "\n",
    "df_active = cuts.selection(df_work, df_work['CutFiducialCylinder1T'], desc='CutFiducialCylinder1T')\n",
    "t42 = root_numpy.array2tree(df_active.to_records())\n",
    "c = ROOT.TCanvas('c','c',900,600)\n",
    "\n",
    "t42.Draw('cs2bottom/100:cs1>>h5(73,200,450,50,30,130)','','COLZ')\n",
    "hist_s2_s1_42kev = ROOT.gDirectory.Get('h5')\n",
    "hist_s2_s1_42kev.GetXaxis().SetTitle('cs1')\n",
    "hist_s2_s1_42kev.GetYaxis().SetTitle('cs2_b')\n",
    "hist_s2_s1_42kev.Sumw2(1)\n",
    "\n",
    "# Reposition the stats box\n",
    "ROOT.gPad.Update()\n",
    "st = hist_s2_s1_42kev.FindObject(\"stats\")\n",
    "st.SetX1NDC(0.725)\n",
    "st.SetX2NDC(0.9)\n",
    "st.SetY1NDC(0.475)\n",
    "st.SetY2NDC(0.875)\n",
    "\n",
    "\n",
    "f7 = ROOT.TF2(\"f7\",\"([0]*TMath::Exp(-0.5*(TMath::Power((((x-[1])*cos([3])-(y-[2])*sin([3]))/[4]),2)+TMath::Power((((x-[1])*sin([3])+(y-[2])*cos([3]))/[5]),2))))+[6]\"\n",
    "              ,280,450,30,130)\n",
    "f7.SetParameter(0, 20)\n",
    "f7.SetParLimits(0,0,100)\n",
    "f7.SetParameter(1, 350)\n",
    "#f7.SetParLimits(1,240,265)\n",
    "f7.SetParameter(2, 70)\n",
    "#f7.SetParLimits(2,350,450)\n",
    "f7.SetParameter(3, 0.4)\n",
    "f7.SetParLimits(3,0.2,1.0);\n",
    "f7.SetParameter(4, 27)\n",
    "f7.SetParameter(5, 30)\n",
    "f7.SetParameter(6, 1)\n",
    "f7.SetParLimits(6,0,5)\n",
    "f7.SetLineColor(2)\n",
    "f7.SetLineWidth(3)\n",
    "f7.SetContour(5, ) #What kind of contours are drawn by default anyway?\n",
    "\n",
    "f7.SetParName(0, \"A_{41.5 keV}\")\n",
    "f7.SetParName(1, \"#mu_{S1, 41.5 keV}\")\n",
    "f7.SetParName(2, \"#mu_{S2, 41.5 keV}\")\n",
    "f7.SetParName(3, \"#phi_{41.5 keV}\")\n",
    "f7.SetParName(4, \"a_{41.5 keV}\")\n",
    "f7.SetParName(5, \"b_{41.5 keV}\")\n",
    "f7.SetParName(6, \"Background\")\n",
    "\n",
    "\n",
    "#ROOT.gPad.SetLogz()\n",
    "\n",
    "\n",
    "fit = hist_s2_s1_42kev.Fit('f7', \"LER\")\n",
    "hist_s2_s1_42kev.GetXaxis().SetTitle('cS1 [pe]')\n",
    "hist_s2_s1_42kev.GetYaxis().SetTitle('cS2_{b}/100 [pe]')\n",
    "hist_s2_s1_42kev.GetYaxis().SetTitleOffset(1.3)\n",
    "hist_s2_s1_42kev.Draw(\"COLZ\")\n",
    "\n",
    "\n",
    "\n",
    "# Get the right errors with option \"E\". Here a mean error is calculated from the asymmetric errors MINOS returns.\n",
    "# The asymmetric errors can be accessed by r.LowerError(<parameter>) and r.UpperError(<parameter>)\n",
    "# Also observe that the \"S\" option is used which lets you access the full covariance matrix, etc. \n",
    "r = ROOT.TFitResultPtr()\n",
    "r = hist_s2_s1_42kev.Fit('f7', \"RLES\")\n",
    "mu_x_42kev_err=r.Error(1)\n",
    "mu_y_42kev_err=r.Error(2)\n",
    "phi_42kev_err=r.Error(3)\n",
    "#phi_80kev_err=r.Error(9)\n",
    "\n",
    "#print(\"Error for cS1 mean =\", mu_x_42kev_err)\n",
    "#print( \"Error for cS2bottom/100 mean =\", mu_y_42kev_err)\n",
    "\n",
    "# Draw the ellipsis main axis\n",
    "#y1=-(xmin-mu_x)+mu_y\n",
    "#y2=-(xmax-mu_x)+mu_y\n",
    "#eline = ROOT.TLine(xmin,y1,xmax,y2)\n",
    "#eline.SetLineWidth(2)\n",
    "#eline.Draw(\"SAME\")\n",
    "\n",
    "\n",
    "#amplitude_42kev = f7.GetParameter(0)\n",
    "mu_x_42kev=f7.GetParameter(1)\n",
    "mu_y_42kev=f7.GetParameter(2)\n",
    "#phi_42kev = f7.GetParameter(3)\n",
    "#a_42kev = f7.GetParameter(4)\n",
    "#b_42kev = f7.GetParameter(5)\n",
    "#phi_80kev = f7.GetParameter(9)\n",
    "\n",
    "#print(\"Light yield is\", mu_x_42kev/164, \"PE/keV\")\n",
    "#print(\"Charge yield is\", mu_y_42kev/100, \"PE/keV\")\n",
    "#print(\"phi = \", phi_42kev)\n",
    "#m = ROOT.TMath.Tan(phi_42kev*3.141/1164)\n",
    "#print(\"Slope of the main axis is\", m)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c.Update()\n",
    "\n",
    "\n",
    "c.SaveAs('s2_s1_42kev.png')\n",
    "c.SaveAs('s2_s1_42kev.pdf')\n",
    "from IPython.display import Image\n",
    "Image(filename='s2_s1_42kev.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def chisquare(function, functionparams, x, y, yerr):\n",
    "    '''Function to calculate the chi2 of a fit with \"function\" that yields \"functionparams\". \n",
    "    Works with up to 7 fit parameters. Returns reduced chi2, chi2, ndof'''\n",
    "    \n",
    "    nparams=len(functionparams)\n",
    "    if nparams==1:    \n",
    "        summands=np.divide(np.power(np.subtract(y,function(x, functionparams[0])),2),np.power(yerr,2))\n",
    "    elif nparams==2:\n",
    "        summands=np.divide(np.power(np.subtract(y,function(x, functionparams[0], functionparams[1])),2),np.power(yerr,2))\n",
    "    elif nparams==3:\n",
    "        summands=np.divide(np.power(np.subtract(y,function(x, functionparams[0], functionparams[1], functionparams[2])),2),np.power(yerr,2))\n",
    "    elif nparams==4:\n",
    "        summands=np.divide(np.power(np.subtract(y,function(x, functionparams[0], functionparams[1], functionparams[2], functionparams[3])),2),np.power(yerr,2))\n",
    "    elif nparams==5:\n",
    "        summands=np.divide(np.power(np.subtract(y,function(x, functionparams[0], functionparams[1], functionparams[2], functionparams[3],functionparams[4])),2),np.power(yerr,2))\n",
    "    elif nparams==6:\n",
    "        summands=np.divide(np.power(np.subtract(y,function(x, functionparams[0], functionparams[1], functionparams[2], functionparams[3],functionparams[4],functionparams[5])),2),np.power(yerr,2))\n",
    "    elif nparams==7:\n",
    "        summands=np.divide(np.power(np.subtract(y,function(x, functionparams[0], functionparams[1], functionparams[2], functionparams[3],functionparams[4],functionparams[5],functionparams[6])),2),np.power(yerr,2))\n",
    "\n",
    "        \n",
    "    ndof=len(x)-len(functionparams)\n",
    "    chi2=np.sum(summands)\n",
    "    chi2ndof=np.divide(chi2,ndof)\n",
    "    #print(summands)\n",
    "    #print(chi2)\n",
    "    #print(ndof)\n",
    "    #print(chi2ndof)\n",
    "    return(chi2ndof, chi2, ndof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Quantities from fit with all points\n",
    "s1=[mu_x_42kev,mu_x_164kev,mu_x_236kev, mu_x_1173kev, mu_x_1332kev]\n",
    "s2=[mu_y_42kev,mu_y_164kev,mu_y_236kev, mu_y_1173kev, mu_y_1332kev]\n",
    "s1errfit=[mu_x_42kev_err,mu_x_164kev_err,mu_x_236kev_err, mu_x_1173kev_err, mu_x_1332kev_err]\n",
    "s2errfit=[mu_y_42kev_err,mu_y_164kev_err,mu_y_236kev_err, mu_y_1173kev_err, mu_y_1332kev_err]\n",
    "#s1errsyst=[1,2,25.7,10,10,10,67]\n",
    "#s2errsyst=[2,4,28.7,10,10,10,60]\n",
    "energy=[41.5, 163.9, 236.2, 1173.2, 1332.5]\n",
    "#s1err=np.sqrt(np.add(np.power(s1errfit,2),np.power(s1errsyst,2)))\n",
    "#s2err=np.sqrt(np.add(np.power(s2errfit,2),np.power(s2errsyst,2)))\n",
    "\n",
    "\n",
    "\n",
    "# Derived quantities\n",
    "s1yield=np.divide(s1,energy)\n",
    "s2yield=np.divide(np.multiply(1,s2),energy)\n",
    "yerr=np.divide(np.multiply(1,s2errfit),energy)\n",
    "xerr=np.divide(s1errfit,energy)\n",
    "\n",
    "# Linear fit\n",
    "def linear1(x,a,b):\n",
    "    return a*x+b\n",
    "\n",
    "initparams=[(-1.40275986, 6.08900108)]\n",
    "linearfitparams, linearfitcovariance = curve_fit(linear1, s1yield, s2yield, initparams, yerr)\n",
    "\n",
    "xvaluesforplot = np.arange(5, 9.5, 0.01)\n",
    "\n",
    "plt.plot(xvaluesforplot, linear1(xvaluesforplot, linearfitparams[0], linearfitparams[1]), \n",
    "         label='$Q=-\\\\alpha \\cdot L_y +(1/\\\\beta)$', color='red', linewidth=3, linestyle=\"--\")\n",
    "\n",
    "print(linearfitparams)\n",
    "print(linearfitcovariance[0][0], linearfitcovariance[1][1])\n",
    "\n",
    "\n",
    "plt.errorbar(s1yield,s2yield,yerr,xerr, marker='o', color='black', linestyle=\"\", markersize=10, label= '$L_y$ and $Q$ from fits')\n",
    "plt.ylabel('$Q_{ee}$ [pe/keV]')\n",
    "plt.xlabel('$L_y$ [pe/keV]')\n",
    "\n",
    "\n",
    "i=0\n",
    "for linevalue in energy:\n",
    "    xvalue=s1yield[i]\n",
    "    yvalue=s2yield[i]\n",
    "    if linevalue > 236 and linevalue < 1000:\n",
    "        plt.text(xvalue-0.9, yvalue, '%5.1f keV' % linevalue)\n",
    "    else:\n",
    "        plt.text(xvalue+0.1, yvalue, '%5.1f keV' % linevalue)    \n",
    "    i=i+1\n",
    "\n",
    "\n",
    "leg = plt.legend(fancybox=True,loc='best',fontsize = 'medium')\n",
    "leg.get_frame().set_alpha(0.5)     \n",
    "\n",
    "\n",
    "ces_a = -linearfitparams[0]*(1/linearfitparams[1])\n",
    "ces_a_err = np.sqrt((linearfitcovariance[0][0]/linearfitparams[1])**2+(linearfitparams[0]*linearfitcovariance[1][1]/(linearfitparams[1])**2)**2)\n",
    "ces_b = 1/linearfitparams[1]\n",
    "ces_b_err= linearfitcovariance[1][1]/(linearfitparams[1])**2\n",
    "\n",
    "g1=(13.7*1e-3)/ces_a\n",
    "g1_err=(13.7*1e-3*ces_a_err)/ces_a**2\n",
    "\n",
    "g2=(13.7*1e-3*100)/ces_b #13.7 comes from an average of 73 quanta/keV (information carriers)\n",
    "g2_err=(13.7*1e-3*100*ces_b_err)/ces_b**2\n",
    "\n",
    "\n",
    "print(\"CES parameter a = %5.4f ± %5.4f\" % (ces_a, ces_a_err))\n",
    "print(\"CES parameter b = %5.4f ± %5.4f\" % (ces_b, ces_b_err))\n",
    "print(\"g1 = %5.4f ± %5.4f\" % (g1, g1_err))\n",
    "print(\"g2 = %5.4f ± %5.4f\" % (g2, g2_err))\n",
    "print(\"Chi2/NDOF is %5.4f\" % chisquare(linear1, linearfitparams, s1yield, s2yield, yerr)[0])\n",
    "\n",
    "plt.text(5.2,1.6, (\"$\\chi^2/ndf= %5.4f$\" % chisquare(linear1, linearfitparams, s1yield, s2yield, yerr)[0]), fontsize=20)\n",
    "plt.text(5.2,1.4, (\"$g_1= (%5.4f \\pm %5.4f)$ pe\" % (g1, g1_err)), fontsize=20)\n",
    "plt.text(5.2,1.2, (\"$g_2= (%5.4f \\pm %5.4f)$ pe\" % (g2, g2_err)), fontsize=20)\n",
    "\n",
    "#plt.text(5.2,2.15, (\"$\\\\alpha= (%5.4f \\pm %5.4f)$ keV/pe\" % (ces_a, np.around(ces_a_err+0.005,2))), fontsize=20)\n",
    "#plt.text(5.2,2.0, (\"$\\\\beta= (%5.4f \\pm %5.4f)$ keV/pe\" % (ces_b, np.around(ces_b_err+0.005,2))), fontsize=20)\n",
    "\n",
    "plt.title('Cross-check of $g_1$ and $g_2$ with PAX 6.6.5 for SR1')\n",
    "plt.savefig('linces.pdf', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Now build a quick CES and search for other lines in the data we can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# lets calculate a rough CES \n",
    "\n",
    "w_value= 0.0137\n",
    "\n",
    "g1 =  0.1471 # 6_4_2 0.9\n",
    "g2 =  11.45 #\n",
    "\n",
    "df_work['CES_tmp'] = w_value*(df_work.cs2bottom/g2 + df_work.cs1/g1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df_work = cuts.selection(df_work, df_work['largest_other_s1'] < 0.1 * df_work['s1'], desc=\"multiscatter cut s1\" ,force_repeat =True )# remove smoothly cuts with a second s2 reasonably high,.1 is experimentally at this point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# CES of 40 keV using an exponentially modified Gaussian (from here many thanks to C.Wittweg for insight in his code))\n",
    "\n",
    "file = ROOT.TFile (\"dec1tsr0.root\",\"RECREATE\")\n",
    "\n",
    "ROOT.gROOT.SetStyle(\"Plain\");   \n",
    "ROOT.gStyle.SetOptStat(1000000010)\n",
    "ROOT.gStyle.SetPalette(57);     \n",
    "ROOT.gStyle.SetOptTitle(0);     \n",
    "ROOT.gStyle.SetOptFit(111)\n",
    "ROOT.TVirtualFitter.SetDefaultFitter(\"Minuit\"); \n",
    "\n",
    "\n",
    "t40b = root_numpy.array2tree(df_work.to_records())\n",
    "c = ROOT.TCanvas('c','c',900,600)\n",
    "\n",
    "t40b.Draw('CES_tmp>>h40kevs1(30,50,80)','','E1')\n",
    "\n",
    "hist_s1_40kev = ROOT.gDirectory.Get('h40kevs1')\n",
    "hist_s1_40kev.GetXaxis().SetTitle('ces [keV]')\n",
    "hist_s1_40kev.GetYaxis().SetTitle('Counts')\n",
    "hist_s1_40kev.Sumw2(1)\n",
    "\n",
    "hist_s1_40kev.Write()\n",
    "\n",
    "# Reposition the stats box\n",
    "ROOT.gPad.Update()\n",
    "st = hist_s1_40kev.FindObject(\"stats\")\n",
    "st.SetX1NDC(0.65)\n",
    "st.SetX2NDC(0.95)\n",
    "st.SetY1NDC(0.65)\n",
    "st.SetY2NDC(0.95)\n",
    "\n",
    "#sigma = 3, tau = 1, mu =2\n",
    "#histfit= ROOT.TF1(\"histfit\", \"gaus(0)+gaus(3)\",25,53)\n",
    "#histfit.SetParameter(0, 50000)\n",
    "#histfit.SetParLimits(0,0,50000)\n",
    "#histfit.SetParameter(1, 31)\n",
    "#histfit.SetParLimits(1,0,35)\n",
    "#histfit.SetParameter(2,3)\n",
    "#histfit.SetParLimits(2, 0,6)\n",
    "#histfit.SetParameter(3, 260000)\n",
    "#histfit.SetParameter(4, 38)\n",
    "#histfit.SetParameter(5, 5)\n",
    "\n",
    "histfit= ROOT.TF1(\"histfit\", \"[3]\",50,80)\n",
    "histfit.SetParameter(0, 3)\n",
    "histfit.SetParameter(1, 64)\n",
    "histfit.SetParLimits(1, 60,68)\n",
    "histfit.SetParameter(2,4)\n",
    "histfit.SetParameter(3, 15)\n",
    "\n",
    "\n",
    "\n",
    "histfit.SetParName(0, \"A_{41.5 keV}\")\n",
    "histfit.SetParName(1, \"#mu_{41.5 keV}\")\n",
    "histfit.SetParName(2, \"#sigma_{41.5 keV}\")\n",
    "histfit.SetParName(3, \"bkg\")\n",
    "\n",
    "\n",
    "histfit.SetLineColor(2)\n",
    "\n",
    "hist_s1_40kev.Fit(\"histfit\",\"LRE\")\n",
    "histfit.Draw(\"same\")\n",
    "\n",
    "mu_x_40kev_1D=histfit.GetParameter(2)\n",
    "mu_x_40kev_1D_err=histfit.GetParError(2)\n",
    "\n",
    "\n",
    "c.Update()\n",
    "\n",
    "c.SaveAs('s1_40kev.png')\n",
    "from IPython.display import Image\n",
    "Image(filename='s1_40kev.png') \n",
    "\n",
    "#c.Write()\n",
    "#file.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate a very rough limit MEI STYLE\n",
    "\n",
    "f_K = 1 # hier erstmal nur für den KK\n",
    "efficiency = 0.9 \n",
    "alpha = 1.64 # fuer 90%\n",
    "M = 1000 # target mass in kg\n",
    "N_A = 6.023e23 # Avogadro-Konstante\n",
    "abundance = 0.1 # easy, right?\n",
    "A = 124 # easy, right?\n",
    "#delta_T = 34.6/365. #livetime\n",
    "delta_T = (run_time_tot_s/(60*60*24))/365\n",
    "delta_E = 3.0 # resolution\n",
    "b = 20.483  # background_rate\n",
    "B = b * delta_E\n",
    "mu_up = alpha * np.sqrt(B)\n",
    "\n",
    "\n",
    "\n",
    "half_life = np.log(2)*efficiency*f_K*abundance*np.sqrt(delta_T)*(M*N_A/A) * (1/mu_up)\n",
    "\n",
    "\n",
    "\n",
    "print(half_life)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
